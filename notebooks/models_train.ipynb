{
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "#@title parameters\n",
    "\n",
    "#model_name = \"bert-base-uncased\"\n",
    "#model_name = \"roberta-base\"\n",
    "model_name = \"microsoft/deberta-base\"\n",
    "\n",
    "random_seed = 42\n",
    "num_workers = 0\n",
    "\n",
    "batch_size = 8\n",
    "learning_rate = 1e-5\n",
    "epochs = 10"
   ],
   "metadata": {
    "id": "HtrE3b24UWSz"
   },
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install transformers"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i5HQy4Db6FpI",
    "outputId": "ca5243fd-b84d-4d1f-dfc9-6146c7ba601b"
   },
   "execution_count": 2,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.25.1-py3-none-any.whl (5.8 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m5.8/5.8 MB\u001B[0m \u001B[31m47.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
      "  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m7.6/7.6 MB\u001B[0m \u001B[31m63.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
      "Collecting huggingface-hub<1.0,>=0.10.0\n",
      "  Downloading huggingface_hub-0.11.1-py3-none-any.whl (182 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m182.4/182.4 KB\u001B[0m \u001B[31m1.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.25.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.4.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (4.0.0)\n",
      "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
      "Successfully installed huggingface-hub-0.11.1 tokenizers-0.13.2 transformers-4.25.1\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "id": "j0fFSA9A4_gV"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "from transformers import  AutoTokenizer, AutoModelForSequenceClassification\n",
    "import numpy as np\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "import torch.optim as optim\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n",
    "torch.cuda.set_device(0)\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(random_seed)\n",
    "    torch.cuda.manual_seed_all(random_seed)\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X2KdmKUo4_gW",
    "outputId": "f0479019-5d9d-4c31-d18d-581689fb0f7b"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "!gdown 1g11MkyTQcuaPHfpFrTNxRw4qzbxiiHWJ #download tran.jsonl\n",
    "!gdown 1h_iDzd-uyOFoxe9n3BH6K9Xc4O77VhCB #validation.jsonl"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6_mha-86HvG5",
    "outputId": "19c394bd-1d5e-4879-bd6e-11fa036c4e75"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1g11MkyTQcuaPHfpFrTNxRw4qzbxiiHWJ\n",
      "To: /content/train.jsonl\n",
      "100% 19.1M/19.1M [00:00<00:00, 101MB/s] \n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1h_iDzd-uyOFoxe9n3BH6K9Xc4O77VhCB\n",
      "To: /content/validation.jsonl\n",
      "100% 5.02M/5.02M [00:00<00:00, 189MB/s]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels = 3)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CG36o1rj4_ga",
    "outputId": "61f7fb20-f355-4a96-e362-d60d95ef5646"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "path = \"/content/\"\n",
    "train = pd.read_json(path + \"train.jsonl\", lines=True)\n",
    "validation = pd.read_json(path + \"validation.jsonl\", lines=True)\n",
    "train"
   ],
   "metadata": {
    "id": "K3yIoQUYOHXh",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "outputId": "b251c8f4-27cb-4daf-9707-4399bf9ccd66"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                      uuid                           postId  \\\n",
       "0     0af11f6b-c889-4520-9372-66ba25cb7657                           532quh   \n",
       "1     b1a1f63d-8853-4a11-89e8-6b2952a393ec               411701128456593408   \n",
       "2     008b7b19-0445-4e16-8f9e-075b73f80ca4               380537005123190784   \n",
       "3     31ecf93c-3e21-4c80-949b-aa549a046b93               844567852531286016   \n",
       "4     31b108a3-c828-421a-a4b9-cf651e9ac859               814186311573766144   \n",
       "...                                    ...                              ...   \n",
       "3195  92578045-699f-4957-a3c5-cff2c3874dae               591979258442027008   \n",
       "3196  51682121-df0b-4289-a95f-e1bc3d181306  881531941974661_902284433232745   \n",
       "3197  9c45ca67-38c4-47b4-aa0d-48434bae09fc               837356193576333314   \n",
       "3198  9d05984c-3920-47c0-aa97-8df58cca1fec               826912122529521666   \n",
       "3199  0d9e3a31-77f7-414a-9d70-5213f2c0cd94               471834972652048385   \n",
       "\n",
       "                                               postText postPlatform  \\\n",
       "0     [Wes Welker Wanted Dinner With Tom Brady, But ...       reddit   \n",
       "1      [NASA sets date for full recovery of ozone hole]      Twitter   \n",
       "2     [This is what makes employees happy -- and it'...      Twitter   \n",
       "3     [Passion is overrated — 7 work habits you need...      Twitter   \n",
       "4     [The perfect way to cook rice so that it's per...      Twitter   \n",
       "...                                                 ...          ...   \n",
       "3195  [Has Facebook's video explosion completely sha...      Twitter   \n",
       "3196  [Cop Is Eating At A Chili's When Teen Hands Hi...     Facebook   \n",
       "3197  [5 popular myths about visible signs of aging ...      Twitter   \n",
       "3198  [You need to see this Twitter account that pre...      Twitter   \n",
       "3199       [GOP congressman comes out for gay marriage]      Twitter   \n",
       "\n",
       "                                       targetParagraphs  \\\n",
       "0     [It’ll be just like old times this weekend for...   \n",
       "1     [2070 is shaping up to be a great year for Mot...   \n",
       "2     [Despite common belief, money isn't the key to...   \n",
       "3     [It’s common wisdom. Near gospel really, and n...   \n",
       "4     [Boiling rice may seem simple, but there is a ...   \n",
       "...                                                 ...   \n",
       "3195  [A long time ago in a galaxy far, far away...W...   \n",
       "3196  [The Kansas City, Kansas Police Department are...   \n",
       "3197  [Obama looks decades younger already, but what...   \n",
       "3198  [What the HELL?!, 1. Unless you’re somewhere w...   \n",
       "3199  [Rep. Charlie Dent (R-Pa.) came out in support...   \n",
       "\n",
       "                                            targetTitle  \\\n",
       "0     Wes Welker Wanted Dinner With Tom Brady, But P...   \n",
       "1     Hole In Ozone Layer Expected To Make Full Reco...   \n",
       "2     Intellectual Stimulation Trumps Money For Empl...   \n",
       "3     ‘Follow your passion’ is wrong, here are 7 hab...   \n",
       "4     Revealed: The perfect way to cook rice so that...   \n",
       "...                                                 ...   \n",
       "3195  Facebook Video Surging, But YouTube Still Offe...   \n",
       "3196  Cop is eating at Chili's when teen hands him f...   \n",
       "3197  5 popular myths about visible signs of aging t...   \n",
       "3198  WTF, It Looks Like This Twitter Account \"Predi...   \n",
       "3199  Pennsylvania GOP Rep. Charlie Dent Comes Out F...   \n",
       "\n",
       "                                      targetDescription  \\\n",
       "0     It'll be just like old times this weekend for ...   \n",
       "1     2070 is shaping up to be a great year for Moth...   \n",
       "2     By: Chad Brooks \\r\\nPublished: 09/18/2013 06:4...   \n",
       "3       There's a lot more to work that loving your job   \n",
       "4     The question 'How does one cook rice properly?...   \n",
       "...                                                 ...   \n",
       "3195                                                  .   \n",
       "3196                                               None   \n",
       "3197  Dozens of anti-wrinkle products and creams are...   \n",
       "3198                                                      \n",
       "3199                          Rep. Charlie Dent (R-Pa.)   \n",
       "\n",
       "                                         targetKeywords  \\\n",
       "0       new england patriots, ricky doyle, top stories,   \n",
       "1     ozone layer,ozone hole determined by weather,M...   \n",
       "2     employee happiness money,employee happiness in...   \n",
       "3                          business, work-life, careers   \n",
       "4               Quora,users,share,perfect,way,cook,rice   \n",
       "...                                                 ...   \n",
       "3195           Facebook,web video,web video ads,YouTube   \n",
       "3196                                               None   \n",
       "3197                                                      \n",
       "3198                                                      \n",
       "3199  lgbt,charlie dent gay marriage,Charlie Dent,pe...   \n",
       "\n",
       "                                            targetMedia  \\\n",
       "0     [http://pixel.wp.com/b.gif?v=noscript, http://...   \n",
       "1     [http://s.m.huffpost.com/assets/Logo_Huffingto...   \n",
       "2     [http://i.huffpost.com/gen/1359674/images/o-HA...   \n",
       "3                                                  None   \n",
       "4                                                  None   \n",
       "...                                                 ...   \n",
       "3195  [http://djcs-prod.s3.amazonaws.com/wsjfrontpag...   \n",
       "3196  [https://sbly-web-prod-shareably.netdna-ssl.co...   \n",
       "3197                                               None   \n",
       "3198                                               None   \n",
       "3199  [http://s.m.huffpost.com/assets/Logo_Huffingto...   \n",
       "\n",
       "                                              targetUrl  \\\n",
       "0     http://nesn.com/2016/09/wes-welker-wanted-dinn...   \n",
       "1                                http://huff.to/1cH672Z   \n",
       "2                                http://huff.to/1epfeaw   \n",
       "3                                                  None   \n",
       "4                                                  None   \n",
       "...                                                 ...   \n",
       "3195                          http://on.wsj.com/1GfyUqz   \n",
       "3196  http://shareably.net/officer-receives-touching...   \n",
       "3197  https://www.businessinsider.in/5-popular-myths...   \n",
       "3198                                               None   \n",
       "3199                             http://huff.to/1kMAadJ   \n",
       "\n",
       "                                             provenance  \\\n",
       "0     {'source': 'anonymized', 'humanSpoiler': 'They...   \n",
       "1     {'source': 'anonymized', 'humanSpoiler': '2070...   \n",
       "2     {'source': 'anonymized', 'humanSpoiler': 'Inte...   \n",
       "3     {'source': 'anonymized', 'humanSpoiler': None,...   \n",
       "4     {'source': 'anonymized', 'humanSpoiler': None,...   \n",
       "...                                                 ...   \n",
       "3195  {'source': 'anonymized', 'humanSpoiler': 'No.'...   \n",
       "3196  {'source': 'anonymized', 'humanSpoiler': 'The ...   \n",
       "3197  {'source': 'anonymized', 'humanSpoiler': None,...   \n",
       "3198  {'source': 'anonymized', 'humanSpoiler': None,...   \n",
       "3199  {'source': 'anonymized', 'humanSpoiler': 'Rep....   \n",
       "\n",
       "                                                spoiler  \\\n",
       "0                 [how about that morning we go throw?]   \n",
       "1                                                [2070]   \n",
       "2                            [intellectual stimulation]   \n",
       "3     [Purpose connects us to something bigger and i...   \n",
       "4                                    [in a rice cooker]   \n",
       "...                                                 ...   \n",
       "3195  [it hasn’t necessarily taken the wind out of Y...   \n",
       "3196           [It read, \"Thanks for keeping us safe.\"]   \n",
       "3197  [1. Anti-wrinkle creams will erase the fine li...   \n",
       "3198                                   [@beyoncefan666]   \n",
       "3199                        [Rep. Charlie Dent (R-Pa.)]   \n",
       "\n",
       "                                       spoilerPositions       tags  \n",
       "0                                [[[3, 151], [3, 186]]]  [passage]  \n",
       "1                                    [[[0, 0], [0, 4]]]   [phrase]  \n",
       "2                                [[[1, 186], [1, 210]]]   [phrase]  \n",
       "3     [[[11, 25], [11, 101]], [[17, 56], [17, 85]], ...    [multi]  \n",
       "4                                  [[[5, 60], [5, 76]]]   [phrase]  \n",
       "...                                                 ...        ...  \n",
       "3195                              [[[7, 50], [7, 118]]]  [passage]  \n",
       "3196                             [[[0, 317], [0, 355]]]  [passage]  \n",
       "3197  [[[6, 0], [6, 73]], [[10, 0], [10, 109]], [[14...    [multi]  \n",
       "3198                               [[[3, 55], [3, 69]]]   [phrase]  \n",
       "3199                                [[[0, 0], [0, 25]]]   [phrase]  \n",
       "\n",
       "[3200 rows x 14 columns]"
      ],
      "text/html": [
       "\n",
       "  <div id=\"df-32d03b13-4868-4e0d-96e3-0cd6c9215495\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uuid</th>\n",
       "      <th>postId</th>\n",
       "      <th>postText</th>\n",
       "      <th>postPlatform</th>\n",
       "      <th>targetParagraphs</th>\n",
       "      <th>targetTitle</th>\n",
       "      <th>targetDescription</th>\n",
       "      <th>targetKeywords</th>\n",
       "      <th>targetMedia</th>\n",
       "      <th>targetUrl</th>\n",
       "      <th>provenance</th>\n",
       "      <th>spoiler</th>\n",
       "      <th>spoilerPositions</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0af11f6b-c889-4520-9372-66ba25cb7657</td>\n",
       "      <td>532quh</td>\n",
       "      <td>[Wes Welker Wanted Dinner With Tom Brady, But ...</td>\n",
       "      <td>reddit</td>\n",
       "      <td>[It’ll be just like old times this weekend for...</td>\n",
       "      <td>Wes Welker Wanted Dinner With Tom Brady, But P...</td>\n",
       "      <td>It'll be just like old times this weekend for ...</td>\n",
       "      <td>new england patriots, ricky doyle, top stories,</td>\n",
       "      <td>[http://pixel.wp.com/b.gif?v=noscript, http://...</td>\n",
       "      <td>http://nesn.com/2016/09/wes-welker-wanted-dinn...</td>\n",
       "      <td>{'source': 'anonymized', 'humanSpoiler': 'They...</td>\n",
       "      <td>[how about that morning we go throw?]</td>\n",
       "      <td>[[[3, 151], [3, 186]]]</td>\n",
       "      <td>[passage]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b1a1f63d-8853-4a11-89e8-6b2952a393ec</td>\n",
       "      <td>411701128456593408</td>\n",
       "      <td>[NASA sets date for full recovery of ozone hole]</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>[2070 is shaping up to be a great year for Mot...</td>\n",
       "      <td>Hole In Ozone Layer Expected To Make Full Reco...</td>\n",
       "      <td>2070 is shaping up to be a great year for Moth...</td>\n",
       "      <td>ozone layer,ozone hole determined by weather,M...</td>\n",
       "      <td>[http://s.m.huffpost.com/assets/Logo_Huffingto...</td>\n",
       "      <td>http://huff.to/1cH672Z</td>\n",
       "      <td>{'source': 'anonymized', 'humanSpoiler': '2070...</td>\n",
       "      <td>[2070]</td>\n",
       "      <td>[[[0, 0], [0, 4]]]</td>\n",
       "      <td>[phrase]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>008b7b19-0445-4e16-8f9e-075b73f80ca4</td>\n",
       "      <td>380537005123190784</td>\n",
       "      <td>[This is what makes employees happy -- and it'...</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>[Despite common belief, money isn't the key to...</td>\n",
       "      <td>Intellectual Stimulation Trumps Money For Empl...</td>\n",
       "      <td>By: Chad Brooks \\r\\nPublished: 09/18/2013 06:4...</td>\n",
       "      <td>employee happiness money,employee happiness in...</td>\n",
       "      <td>[http://i.huffpost.com/gen/1359674/images/o-HA...</td>\n",
       "      <td>http://huff.to/1epfeaw</td>\n",
       "      <td>{'source': 'anonymized', 'humanSpoiler': 'Inte...</td>\n",
       "      <td>[intellectual stimulation]</td>\n",
       "      <td>[[[1, 186], [1, 210]]]</td>\n",
       "      <td>[phrase]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31ecf93c-3e21-4c80-949b-aa549a046b93</td>\n",
       "      <td>844567852531286016</td>\n",
       "      <td>[Passion is overrated — 7 work habits you need...</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>[It’s common wisdom. Near gospel really, and n...</td>\n",
       "      <td>‘Follow your passion’ is wrong, here are 7 hab...</td>\n",
       "      <td>There's a lot more to work that loving your job</td>\n",
       "      <td>business, work-life, careers</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>{'source': 'anonymized', 'humanSpoiler': None,...</td>\n",
       "      <td>[Purpose connects us to something bigger and i...</td>\n",
       "      <td>[[[11, 25], [11, 101]], [[17, 56], [17, 85]], ...</td>\n",
       "      <td>[multi]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31b108a3-c828-421a-a4b9-cf651e9ac859</td>\n",
       "      <td>814186311573766144</td>\n",
       "      <td>[The perfect way to cook rice so that it's per...</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>[Boiling rice may seem simple, but there is a ...</td>\n",
       "      <td>Revealed: The perfect way to cook rice so that...</td>\n",
       "      <td>The question 'How does one cook rice properly?...</td>\n",
       "      <td>Quora,users,share,perfect,way,cook,rice</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>{'source': 'anonymized', 'humanSpoiler': None,...</td>\n",
       "      <td>[in a rice cooker]</td>\n",
       "      <td>[[[5, 60], [5, 76]]]</td>\n",
       "      <td>[phrase]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3195</th>\n",
       "      <td>92578045-699f-4957-a3c5-cff2c3874dae</td>\n",
       "      <td>591979258442027008</td>\n",
       "      <td>[Has Facebook's video explosion completely sha...</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>[A long time ago in a galaxy far, far away...W...</td>\n",
       "      <td>Facebook Video Surging, But YouTube Still Offe...</td>\n",
       "      <td>.</td>\n",
       "      <td>Facebook,web video,web video ads,YouTube</td>\n",
       "      <td>[http://djcs-prod.s3.amazonaws.com/wsjfrontpag...</td>\n",
       "      <td>http://on.wsj.com/1GfyUqz</td>\n",
       "      <td>{'source': 'anonymized', 'humanSpoiler': 'No.'...</td>\n",
       "      <td>[it hasn’t necessarily taken the wind out of Y...</td>\n",
       "      <td>[[[7, 50], [7, 118]]]</td>\n",
       "      <td>[passage]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3196</th>\n",
       "      <td>51682121-df0b-4289-a95f-e1bc3d181306</td>\n",
       "      <td>881531941974661_902284433232745</td>\n",
       "      <td>[Cop Is Eating At A Chili's When Teen Hands Hi...</td>\n",
       "      <td>Facebook</td>\n",
       "      <td>[The Kansas City, Kansas Police Department are...</td>\n",
       "      <td>Cop is eating at Chili's when teen hands him f...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[https://sbly-web-prod-shareably.netdna-ssl.co...</td>\n",
       "      <td>http://shareably.net/officer-receives-touching...</td>\n",
       "      <td>{'source': 'anonymized', 'humanSpoiler': 'The ...</td>\n",
       "      <td>[It read, \"Thanks for keeping us safe.\"]</td>\n",
       "      <td>[[[0, 317], [0, 355]]]</td>\n",
       "      <td>[passage]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3197</th>\n",
       "      <td>9c45ca67-38c4-47b4-aa0d-48434bae09fc</td>\n",
       "      <td>837356193576333314</td>\n",
       "      <td>[5 popular myths about visible signs of aging ...</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>[Obama looks decades younger already, but what...</td>\n",
       "      <td>5 popular myths about visible signs of aging t...</td>\n",
       "      <td>Dozens of anti-wrinkle products and creams are...</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>https://www.businessinsider.in/5-popular-myths...</td>\n",
       "      <td>{'source': 'anonymized', 'humanSpoiler': None,...</td>\n",
       "      <td>[1. Anti-wrinkle creams will erase the fine li...</td>\n",
       "      <td>[[[6, 0], [6, 73]], [[10, 0], [10, 109]], [[14...</td>\n",
       "      <td>[multi]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3198</th>\n",
       "      <td>9d05984c-3920-47c0-aa97-8df58cca1fec</td>\n",
       "      <td>826912122529521666</td>\n",
       "      <td>[You need to see this Twitter account that pre...</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>[What the HELL?!, 1. Unless you’re somewhere w...</td>\n",
       "      <td>WTF, It Looks Like This Twitter Account \"Predi...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>{'source': 'anonymized', 'humanSpoiler': None,...</td>\n",
       "      <td>[@beyoncefan666]</td>\n",
       "      <td>[[[3, 55], [3, 69]]]</td>\n",
       "      <td>[phrase]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3199</th>\n",
       "      <td>0d9e3a31-77f7-414a-9d70-5213f2c0cd94</td>\n",
       "      <td>471834972652048385</td>\n",
       "      <td>[GOP congressman comes out for gay marriage]</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>[Rep. Charlie Dent (R-Pa.) came out in support...</td>\n",
       "      <td>Pennsylvania GOP Rep. Charlie Dent Comes Out F...</td>\n",
       "      <td>Rep. Charlie Dent (R-Pa.)</td>\n",
       "      <td>lgbt,charlie dent gay marriage,Charlie Dent,pe...</td>\n",
       "      <td>[http://s.m.huffpost.com/assets/Logo_Huffingto...</td>\n",
       "      <td>http://huff.to/1kMAadJ</td>\n",
       "      <td>{'source': 'anonymized', 'humanSpoiler': 'Rep....</td>\n",
       "      <td>[Rep. Charlie Dent (R-Pa.)]</td>\n",
       "      <td>[[[0, 0], [0, 25]]]</td>\n",
       "      <td>[phrase]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3200 rows × 14 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-32d03b13-4868-4e0d-96e3-0cd6c9215495')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-32d03b13-4868-4e0d-96e3-0cd6c9215495 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-32d03b13-4868-4e0d-96e3-0cd6c9215495');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "def delete_brackets_tags(dataframe):\n",
    "    for index, data_row in dataframe.iterrows():\n",
    "            data_row[\"tags\"] = data_row[\"tags\"][0]\n",
    "    return dataframe\n",
    "\n",
    "train = delete_brackets_tags(train)\n",
    "validation = delete_brackets_tags(validation)"
   ],
   "metadata": {
    "id": "Q2J8tBVCxcgb"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def data_processing(dataframe):\n",
    "    ret = []\n",
    "    for _, i in dataframe.iterrows():\n",
    "        post_words = i['postText'][0].split(' ')\n",
    "        if post_words[-1][-1] not in '!?.':\n",
    "            post_words[-1] += '.'\n",
    "\n",
    "        target_paragraphs = i['targetParagraphs']\n",
    "        if len(target_paragraphs) > 2:\n",
    "            target_paragraphs = target_paragraphs[1:]\n",
    "\n",
    "        target_paragraphs_words = []\n",
    "        for paragraph in target_paragraphs:\n",
    "            paragraph_words = paragraph.split(' ')\n",
    "            target_paragraphs_words.extend(paragraph_words)\n",
    "            if len(target_paragraphs_words) >= 201:\n",
    "                target_paragraphs_words = target_paragraphs_words[:201]\n",
    "                break\n",
    "\n",
    "        final_string = ' '.join(post_words) + ' ' + ' '.join(target_paragraphs_words)\n",
    "        ret += [{'text': final_string, 'uuid': i['uuid']}]\n",
    "\n",
    "    return pd.DataFrame(ret)\n",
    "\n",
    "train_data = data_processing(train)\n",
    "validation_data = data_processing(validation)\n",
    "\n",
    "labels_idx = {\"multi\": 0,\t\"passage\": 1, \"phrase\": 2}\n",
    "\n",
    "\n",
    "train_labels = [labels_idx[tag] for tag in train.tags]\n",
    "validation_labels = [labels_idx[tag] for tag in validation.tags]"
   ],
   "metadata": {
    "id": "GP-PEPb6NUx8"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "train_tokens = tokenizer(train_data.text.tolist(), padding=True, truncation=True, max_length=512,\n",
    "                              return_tensors=\"pt\")\n",
    "validation_tokens = tokenizer(validation_data.text.tolist(), padding=True, truncation=True, max_length=512,\n",
    "                              return_tensors=\"pt\")"
   ],
   "metadata": {
    "id": "Ub_VJixkeFji"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "train_inputs = train_tokens[\"input_ids\"].clone().detach()\n",
    "train_masks = train_tokens[\"attention_mask\"].clone().detach()\n",
    "train_labels = torch.tensor(train_labels)\n",
    "\n",
    "val_inputs = validation_tokens[\"input_ids\"].clone().detach()\n",
    "val_masks = validation_tokens[\"attention_mask\"].clone().detach()\n",
    "val_labels = torch.tensor(validation_labels)\n",
    "\n",
    "\n",
    "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size, num_workers=num_workers)\n",
    "\n",
    "val_data = TensorDataset(val_inputs, val_masks, val_labels)\n",
    "val_sampler = SequentialSampler(val_data)\n",
    "val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=batch_size, num_workers=num_workers)\n"
   ],
   "metadata": {
    "id": "w-ZlGvy9lv89"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "optimizer = optim.AdamW(model.parameters(), lr = learning_rate)\n",
    "\n",
    "model = model.to(device)"
   ],
   "metadata": {
    "id": "oTCRSeJm4_gd"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def train_epoch(dataloader, model):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    s = 0\n",
    "    for step, batch  in enumerate(dataloader, 0):\n",
    "        input_id, mask, labels = batch\n",
    "        input_id, mask, labels = input_id.to(device), mask.to(device), labels.to(device)\n",
    "        # zero the parameter gradients\n",
    "        model.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        preds = model(input_id, attention_mask = mask, labels=labels)\n",
    "        # compute the loss between actual and predicted values\n",
    "        loss = preds[0]\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        s+=1\n",
    "    return running_loss / s\n",
    "\n",
    "def evaluate(dataloader, model):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        good = 0\n",
    "        all = 0\n",
    "        for step, batch  in enumerate(dataloader, 0):\n",
    "            sent_id, mask, labels = batch\n",
    "            preds = model(sent_id.to(device), mask.to(device))\n",
    "            preds = np.argmax(preds.logits.cpu(), axis=1).tolist()\n",
    "\n",
    "            for i in range(len(preds)):\n",
    "                if preds[i] == labels[i]:\n",
    "                    good +=1\n",
    "                all +=1\n",
    "    return good/all"
   ],
   "metadata": {
    "id": "bcHyNCFLt2lo"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[1/10] loss: 1.0228781268\n",
      "[1/10] accuracy on eval set: 0.5050000000\n",
      "[2/10] loss: 0.9267705923\n",
      "[2/10] accuracy on eval set: 0.6112500000\n",
      "[3/10] loss: 0.7455242936\n",
      "[3/10] accuracy on eval set: 0.6662500000\n",
      "[4/10] loss: 0.5160093827\n",
      "[4/10] accuracy on eval set: 0.6750000000\n",
      "[5/10] loss: 0.2822443391\n",
      "[5/10] accuracy on eval set: 0.6825000000\n",
      "[6/10] loss: 0.1683545157\n",
      "[6/10] accuracy on eval set: 0.6612500000\n",
      "[7/10] loss: 0.0843735283\n",
      "[7/10] accuracy on eval set: 0.6737500000\n",
      "[8/10] loss: 0.0486120276\n",
      "[8/10] accuracy on eval set: 0.6600000000\n",
      "[9/10] loss: 0.0356756165\n",
      "[9/10] accuracy on eval set: 0.6587500000\n",
      "[10/10] loss: 0.0323740523\n",
      "[10/10] accuracy on eval set: 0.6500000000\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):  # loop over the dataset multiple times\n",
    "    for phase in [\"train\", \"eval\"]:\n",
    "        if phase == \"train\":\n",
    "            epoch_loss = train_epoch(train_dataloader, model)\n",
    "            print('[%d/10] loss: %.10f' % (epoch+1 ,  epoch_loss))\n",
    "        elif phase == \"eval\":\n",
    "            eval_acc = evaluate(val_dataloader, model)\n",
    "            print('[%d/10] accuracy on eval set: %.10f' % (epoch+1 ,  eval_acc))\n",
    "   \n",
    "    model.save_pretrained(f\"/content/{model_name}-{eval_acc}\")\n",
    "print('Finished Training')\n"
   ],
   "metadata": {
    "id": "87QWsXy-4_gd",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "664b6501-fb44-45b3-e441-31b5d8d47df0"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "model_name"
   ],
   "metadata": {
    "id": "EEhWH4g7Ma71",
    "outputId": "591d6d99-a45a-4715-93d9-3ab4402f47f3",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'bert-base-uncased'"
      ],
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      }
     },
     "metadata": {},
     "execution_count": 17
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "#tokenizer.save_pretrained(\"/content/bert-tokenizer\")\n",
    "#!zip -r /content/bert.zip /content/bert-base-uncased-0.6825/\n",
    "#!zip -r /content/bert-tokenizer.zip /content/bert-tokenizer/"
   ],
   "metadata": {
    "id": "DCXn4xtK6gjl",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "e64eb853-2c70-46bf-e759-cf716f6b03ab"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "  adding: content/bert-base-uncased-0.6825/ (stored 0%)\n",
      "  adding: content/bert-base-uncased-0.6825/pytorch_model.bin (deflated 7%)\n",
      "  adding: content/bert-base-uncased-0.6825/config.json (deflated 51%)\n",
      "  adding: content/bert-tokenizer/ (stored 0%)\n",
      "  adding: content/bert-tokenizer/special_tokens_map.json (deflated 42%)\n",
      "  adding: content/bert-tokenizer/vocab.txt (deflated 53%)\n",
      "  adding: content/bert-tokenizer/tokenizer_config.json (deflated 41%)\n",
      "  adding: content/bert-tokenizer/tokenizer.json (deflated 71%)\n"
     ]
    }
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "colab": {
   "provenance": []
  },
  "accelerator": "GPU",
  "gpuClass": "standard"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
